{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b9746454-8dd9-4ffd-9ecc-811af3c05964",
      "metadata": {
        "id": "b9746454-8dd9-4ffd-9ecc-811af3c05964"
      },
      "source": [
        "Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "qeaYyxhQTx3C",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeaYyxhQTx3C",
        "outputId": "18b6f68f-0a71-4eb5-c133-d1eba82b6042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  projects.zip\n",
            "replace projects/simple_calculator/calculator.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip projects.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "80LiV8QdUGuq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80LiV8QdUGuq",
        "outputId": "420b02f6-0170-4a39-d586-7137c512e591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied: /content/projects/file_manager/file_operations.py to .\n",
            "Copied: /content/projects/data_processor/processor.py to .\n",
            "Copied: /content/projects/simple_calculator/calculator.py to .\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def fetch_and_copy_py_files(src_path, dest_path):\n",
        "    \"\"\"\n",
        "    Fetch all Python files from nested folders and copy them to the current directory.\n",
        "\n",
        "    Parameters:\n",
        "    src_path (str): The source directory to search for Python files.\n",
        "    dest_path (str): The destination directory to copy the Python files.\n",
        "    \"\"\"\n",
        "    for root, dirs, files in os.walk(src_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.py'):\n",
        "                full_file_path = os.path.join(root, file)\n",
        "                shutil.copy(full_file_path, dest_path)\n",
        "                print(f\"Copied: {full_file_path} to {dest_path}\")\n",
        "\n",
        "# Example usage\n",
        "source_directory = '/content/projects'\n",
        "destination_directory = '.'  # Current directory\n",
        "fetch_and_copy_py_files(source_directory, destination_directory)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "Y6n5aGThWfXs",
      "metadata": {
        "id": "Y6n5aGThWfXs"
      },
      "outputs": [],
      "source": [
        "def create_empty_txt_file(file_path):\n",
        "    with open(file_path, 'w') as file:\n",
        "        pass  # The pass statement is a no-op; the file is created and left empty.\n",
        "\n",
        "# Example usage\n",
        "create_empty_txt_file('analysis_report.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0200a6e0-f1bf-4d0c-8fcd-5a5f16fd43ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0200a6e0-f1bf-4d0c-8fcd-5a5f16fd43ac",
        "outputId": "2f290cec-7d9a-4cd0-b333-1d713e702a82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pynguin\n",
            "  Downloading pynguin-0.38.0-py3-none-any.whl (307 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/307.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m235.5/307.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.8/307.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2<4.0.0,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from pynguin) (3.1.4)\n",
            "Collecting Pygments<3.0.0,>=2.18.0 (from pynguin)\n",
            "  Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asciitree<0.4.0,>=0.3.3 (from pynguin)\n",
            "  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting astroid<4.0.0,>=3.2.2 (from pynguin)\n",
            "  Downloading astroid-3.2.2-py3-none-any.whl (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.3/276.3 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black<25.0.0,>=24.4.2 (from pynguin)\n",
            "  Downloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bytecode<0.16.0,>=0.15.1 (from pynguin)\n",
            "  Downloading bytecode-0.15.1-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: jellyfish<2.0.0,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from pynguin) (1.0.4)\n",
            "Collecting libcst<2.0.0,>=1.4.0 (from pynguin)\n",
            "  Downloading libcst-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx<4.0,>=3.3 in /usr/local/lib/python3.10/dist-packages (from pynguin) (3.3)\n",
            "Collecting pytest<9.0.0,>=8.2.2 (from pynguin)\n",
            "  Downloading pytest-8.2.2-py3-none-any.whl (339 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m339.9/339.9 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich<14.0.0,>=13.7.1 in /usr/local/lib/python3.10/dist-packages (from pynguin) (13.7.1)\n",
            "Requirement already satisfied: simple-parsing<0.2.0,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from pynguin) (0.1.5)\n",
            "Collecting typing_inspect<0.10.0,>=0.9.0 (from pynguin)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from astroid<4.0.0,>=3.2.2->pynguin) (4.12.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black<25.0.0,>=24.4.2->pynguin) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black<25.0.0,>=24.4.2->pynguin)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from black<25.0.0,>=24.4.2->pynguin) (24.1)\n",
            "Collecting pathspec>=0.9.0 (from black<25.0.0,>=24.4.2->pynguin)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black<25.0.0,>=24.4.2->pynguin) (4.2.2)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black<25.0.0,>=24.4.2->pynguin) (2.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4.0.0,>=3.1.4->pynguin) (2.1.5)\n",
            "Requirement already satisfied: pyyaml>=5.2 in /usr/local/lib/python3.10/dist-packages (from libcst<2.0.0,>=1.4.0->pynguin) (6.0.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.2.2->pynguin) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.2.2->pynguin) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.2.2->pynguin) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.1->pynguin) (3.0.0)\n",
            "Requirement already satisfied: docstring-parser~=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing<0.2.0,>=0.1.5->pynguin) (0.16)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.1->pynguin) (0.1.2)\n",
            "Building wheels for collected packages: asciitree\n",
            "  Building wheel for asciitree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5034 sha256=b6f130ff1de3abc7db75e1648aba450c7a0b8a07b9fde65005c51403a046693c\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/4e/be/1171b40f43b918087657ec57cf3b81fa1a2e027d8755baa184\n",
            "Successfully built asciitree\n",
            "Installing collected packages: asciitree, pytest, Pygments, pathspec, mypy-extensions, libcst, bytecode, astroid, typing_inspect, black, pynguin\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.4.4\n",
            "    Uninstalling pytest-7.4.4:\n",
            "      Successfully uninstalled pytest-7.4.4\n",
            "  Attempting uninstall: Pygments\n",
            "    Found existing installation: Pygments 2.16.1\n",
            "    Uninstalling Pygments-2.16.1:\n",
            "      Successfully uninstalled Pygments-2.16.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pygments-2.18.0 asciitree-0.3.3 astroid-3.2.2 black-24.4.2 bytecode-0.15.1 libcst-1.4.0 mypy-extensions-1.0.0 pathspec-0.12.1 pynguin-0.38.0 pytest-8.2.2 typing_inspect-0.9.0\n",
            "Collecting radon\n",
            "  Downloading radon-6.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mando<0.8,>=0.6 (from radon)\n",
            "  Downloading mando-0.7.1-py2.py3-none-any.whl (28 kB)\n",
            "Collecting colorama>=0.4.1 (from radon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mando<0.8,>=0.6->radon) (1.16.0)\n",
            "Installing collected packages: mando, colorama, radon\n",
            "Successfully installed colorama-0.4.6 mando-0.7.1 radon-6.0.1\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (8.2.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest) (24.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.1)\n",
            "Collecting coverage\n",
            "  Downloading coverage-7.5.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.1/233.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: coverage\n",
            "Successfully installed coverage-7.5.4\n",
            "\u001b[31mERROR: Invalid requirement: '=='\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pynguin\n",
        "!pip install radon\n",
        "!pip install pytest\n",
        "!pip install coverage\n",
        "!pip install openai==0.28\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ff54052-2716-4935-a90a-6842c3ec2b13",
      "metadata": {
        "id": "6ff54052-2716-4935-a90a-6842c3ec2b13"
      },
      "source": [
        "Function to check for Mccabe Complexity of Source Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "990e5792-0318-4dd2-993c-242bfef209e0",
      "metadata": {
        "id": "990e5792-0318-4dd2-993c-242bfef209e0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from radon.complexity import cc_visit\n",
        "\n",
        "# Function to get McCabe complexity\n",
        "def get_mccabe_complexity(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        code = file.read()\n",
        "    complexity_data = cc_visit(code)\n",
        "    total_complexity = sum(c.complexity for c in complexity_data)\n",
        "    return total_complexity\n",
        "\n",
        "# Function to select core modules\n",
        "def select_core_modules(directory):\n",
        "    core_modules = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith('.py'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                file_complexity = get_mccabe_complexity(file_path)\n",
        "                core_modules.append((file_path, file_complexity))\n",
        "\n",
        "    # Sort by complexity\n",
        "    core_modules.sort(key=lambda x: -x[1])  # Sort by complexity only\n",
        "    return core_modules"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3x4T-A8rX1uw",
      "metadata": {
        "id": "3x4T-A8rX1uw"
      },
      "source": [
        "Normal Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fead849e-3d6d-40be-bbc3-04b0383def06",
      "metadata": {
        "id": "fead849e-3d6d-40be-bbc3-04b0383def06"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "#Use Open AI API KEY\n",
        "openai.api_key=\"sk-\"\n",
        "def generate_test_cases(file_path):\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        function_code = file.read()\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    The following is a Python program:\n",
        "\n",
        "    {function_code}\n",
        "\n",
        "    Write Unit tests using Pytest for given Python code that covers all the edge cases.\n",
        "\n",
        "    Give Unit tests code only and no additional text such that it can be directly copied for execution without any modification.\n",
        "\n",
        "    Clearly mention the name of the module to be used take the reference from file path: {file_path}\n",
        "    ###Do not include this line in generated tests: \"```python\"\n",
        "    \"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=1500,\n",
        "        top_p=0.9,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6ecc8e2d-421e-437e-891d-5e7fb0c0aa40",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ecc8e2d-421e-437e-891d-5e7fb0c0aa40",
        "outputId": "81d088da-dbfc-4f30-e5af-b381109427e6",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "import os\n",
            "import tempfile\n",
            "from file_operations import FileManager\n",
            "import pytest\n",
            "\n",
            "@pytest.fixture\n",
            "def file_manager():\n",
            "    base_directory = tempfile.mkdtemp()\n",
            "    return FileManager(base_directory)\n",
            "\n",
            "def test_create_file(file_manager):\n",
            "    file_name = 'test.txt'\n",
            "    content = 'Hello, World!'\n",
            "    file_path = file_manager.create_file(file_name, content)\n",
            "    assert os.path.exists(file_path)\n",
            "    with open(file_path, 'r') as file:\n",
            "        assert file.read() == content\n",
            "\n",
            "def test_read_file(file_manager):\n",
            "    file_name = 'test.txt'\n",
            "    content = 'Hello, World!'\n",
            "    file_manager.create_file(file_name, content)\n",
            "    assert file_manager.read_file(file_name) == content\n",
            "\n",
            "def test_delete_file(file_manager):\n",
            "    file_name = 'test.txt'\n",
            "    file_manager.create_file(file_name)\n",
            "    assert file_manager.delete_file(file_name) == True\n",
            "    assert not os.path.exists(os.path.join(file_manager.base_directory, file_name))\n",
            "    assert file_manager.delete_file(file_name) == False\n",
            "\n",
            "def test_list_files(file_manager):\n",
            "    file_names = ['file1.txt', 'file2.txt', 'file3.txt']\n",
            "    for file_name in file_names:\n",
            "        file_manager.create_file(file_name)\n",
            "    assert set(file_manager.list_files()) == set(file_names)\n"
          ]
        }
      ],
      "source": [
        "print(generate_test_cases('file_operations.py'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5aD2XcdiX4_k",
      "metadata": {
        "id": "5aD2XcdiX4_k"
      },
      "source": [
        "# Approach 1 using Few Shot Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6be3fd5d-6a22-480c-8085-9e34f8856cb7",
      "metadata": {
        "id": "6be3fd5d-6a22-480c-8085-9e34f8856cb7"
      },
      "source": [
        "Create Manual Testing Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "17a4b828-87f0-4a13-9326-7b6ab63f8ed6",
      "metadata": {
        "id": "17a4b828-87f0-4a13-9326-7b6ab63f8ed6"
      },
      "outputs": [],
      "source": [
        "few_shot_examples = \"\"\"\n",
        "import pytest\n",
        "from calculator import Calculator\n",
        "\n",
        "def test_add():\n",
        "    calc = Calculator()\n",
        "    result = calc.add(5, 7)\n",
        "    assert result == 12\n",
        "\n",
        "def test_subtract():\n",
        "    calc = Calculator()\n",
        "    result = calc.subtract(10, 5)\n",
        "    assert result == 5\n",
        "\n",
        "def test_multiply():\n",
        "    calc = Calculator()\n",
        "    result = calc.multiply(3, 7)\n",
        "    assert result == 21\n",
        "\n",
        "def test_divide():\n",
        "    calc = Calculator()\n",
        "    result = calc.divide(10, 2)\n",
        "    assert result == 5\n",
        "\"\"\"\n",
        "def generate_test_cases_fewshot(file_path,few_shot_examples):\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        function_code = file.read()\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    The following is a Python program:\n",
        "\n",
        "    {function_code}\n",
        "\n",
        "    Here are some examples of unit tests using Pytest:\n",
        "\n",
        "    {few_shot_examples}\n",
        "\n",
        "    Write additional unit tests using Pytest for the given Python code that covers all the edge cases.\n",
        "\n",
        "    Give unit tests code only and no additional text such that it can be directly copied for execution without any modification.\n",
        "\n",
        "    Clearly mention the name of the module to be used, taking the reference from file path: {file_path}\n",
        "    ###Do not include this line in generated tests: \"```python\"\n",
        "    \"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=1500,\n",
        "        top_p=0.9,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "41e6a641-8c85-4830-99e8-da6ab8bd228a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41e6a641-8c85-4830-99e8-da6ab8bd228a",
        "outputId": "469c8ca9-fcc7-4d71-d563-805fb1aa41e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "import pytest\n",
            "from calculator import Calculator\n",
            "\n",
            "def test_divide_by_zero():\n",
            "    calc = Calculator()\n",
            "    with pytest.raises(ValueError):\n",
            "        calc.divide(10, 0)\n",
            "\n",
            "def test_power():\n",
            "    calc = Calculator()\n",
            "    result = calc.power(2, 3)\n",
            "    assert result == 8\n",
            "\n",
            "def test_power_zero_exponent():\n",
            "    calc = Calculator()\n",
            "    result = calc.power(2, 0)\n",
            "    assert result == 1\n",
            "\n",
            "def test_power_zero_base():\n",
            "    calc = Calculator()\n",
            "    result = calc.power(0, 5)\n",
            "    assert result == 0\n",
            "\n",
            "def test_factorial():\n",
            "    calc = Calculator()\n",
            "    result = calc.factorial(5)\n",
            "    assert result == 120\n",
            "\n",
            "def test_factorial_zero():\n",
            "    calc = Calculator()\n",
            "    result = calc.factorial(0)\n",
            "    assert result == 1\n",
            "\n",
            "def test_factorial_negative():\n",
            "    calc = Calculator()\n",
            "    with pytest.raises(ValueError):\n",
            "        calc.factorial(-5)\n"
          ]
        }
      ],
      "source": [
        "print(generate_test_cases_fewshot('calculator.py',few_shot_examples))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9bfbca1-f504-44d6-a332-a39cec3d598f",
      "metadata": {
        "id": "c9bfbca1-f504-44d6-a332-a39cec3d598f"
      },
      "source": [
        "# Approach 2: Use Test Generation from Pynquin and LLM and Combine Results with Iterative Improvement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5891ad02-436e-43e0-be97-bf329d2924d6",
      "metadata": {
        "id": "5891ad02-436e-43e0-be97-bf329d2924d6",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "def generate_test_cases_with_pynguin(module_name):\n",
        "    \"\"\"Generate test cases using Pynguin.\"\"\"\n",
        "    os.environ['PYNGUIN_DANGER_AWARE'] = 'YES'\n",
        "    subprocess.run([\n",
        "        'pynguin',\n",
        "        '--project-path', './',\n",
        "        '--output-path', './',\n",
        "        '--module-name', module_name,\n",
        "        '-v'\n",
        "    ])\n",
        "\n",
        "#generate_test_cases_with_pynguin('calculator')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0791768-d4fc-4b0a-a1c8-3d7d86b03e65",
      "metadata": {
        "id": "e0791768-d4fc-4b0a-a1c8-3d7d86b03e65"
      },
      "source": [
        "Check Coverage of Test Cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d7582946-4456-4dc5-a74d-cef2905562cb",
      "metadata": {
        "id": "d7582946-4456-4dc5-a74d-cef2905562cb"
      },
      "outputs": [],
      "source": [
        "# Example usage:\n",
        "def evaluate_coverage(file_path):\n",
        "\n",
        "    code_string =   f\"\"\"\n",
        "import os\n",
        "import coverage\n",
        "import inspect\n",
        "import pytest\n",
        "import json\n",
        "import subprocess\n",
        "\n",
        "# Discover and run all test functions in test_calculator module\n",
        "\n",
        "pytest.main(['-v', '--tb=short', '{file_path}'])\n",
        "subprocess.run(['coverage', 'run', '-m', 'pytest', '{file_path}'])\n",
        "subprocess.run(['coverage', 'json', '-o', 'coverage.json'])\n",
        "\n",
        "# Generate the coverage report\n",
        "subprocess.run(['coverage', 'report', '-m'])\n",
        "\n",
        "with open('coverage.json') as f:\n",
        "        coverage_data = json.load(f)\n",
        "\n",
        "# Extract the file coverage information\n",
        "file_coverage = coverage_data['files'].get('{file_path}')\n",
        "if file_coverage:\n",
        "    executable = file_coverage['executed_lines']\n",
        "    executed = file_coverage['executed_lines']\n",
        "    missing = file_coverage['missing_lines']\n",
        "    excluded = file_coverage['excluded_lines']\n",
        "    print(f\"File: {file_path}\")\n",
        "    print(f\"Executable Lines: {{executable}}\")\n",
        "    print(f\"Executed Lines: {{executed}}\")\n",
        "    print(f\"Missed Lines: {{missing}}\")\n",
        "    print(f\"Excluded Lines: {{excluded}}\")\n",
        "    report_file='analysis_report.txt'\n",
        "    with open(report_file, 'w') as report:\n",
        "        report.write(f\"Missed lines: {{missing}}\")\n",
        "else:\n",
        "   print(\"Failed\")\n",
        "                    \"\"\"\n",
        "    filename='run_coverage.py'\n",
        "    if not filename.endswith('.py'):\n",
        "            filename += '.py'\n",
        "\n",
        "    # Write the code string to the file\n",
        "    with open(filename, 'w') as file:\n",
        "        file.write(code_string)\n",
        "    !python run_coverage.py\n",
        "    #return missed_lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5763dbc8-4d84-46d4-b5b3-53fd9c0b1636",
      "metadata": {
        "id": "5763dbc8-4d84-46d4-b5b3-53fd9c0b1636"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "def get_missed_statements(report_path):\n",
        "    \"\"\"\n",
        "    Extracts missed statements from a coverage report in a text file.\n",
        "\n",
        "    Parameters:\n",
        "    report_path (str): The path to the text coverage report file.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of missed statements.\n",
        "    \"\"\"\n",
        "    missed_statements = []\n",
        "\n",
        "    with open(report_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Regular expression to match the missed lines\n",
        "    missed_lines_pattern = re.compile(r\"Missed lines:\\s*\\[([0-9,\\s]*)\\]\")\n",
        "\n",
        "    for line in lines:\n",
        "        match = missed_lines_pattern.search(line)\n",
        "        if match:\n",
        "            missed_lines_str = match.group(1).strip()\n",
        "            if missed_lines_str:\n",
        "                missed_lines = [int(x.strip()) for x in missed_lines_str.split(',') if x.strip().isdigit()]\n",
        "                missed_statements.extend(missed_lines)\n",
        "\n",
        "    print(missed_statements)\n",
        "    return missed_statements\n",
        "\n",
        "def iterative_improvement(file_path, module_name):\n",
        "    with open(file_path, 'r') as file:\n",
        "        code = file.read()\n",
        "\n",
        "    pynguin_test_file = './test_' + module_name.replace('.', '_') + '.py'\n",
        "    generate_test_cases_with_pynguin(module_name)\n",
        "\n",
        "    improved_tests = generate_test_cases(file_path)\n",
        "    mess = \"Here are the unit tests using Pytest:\"\n",
        "    if(improved_tests[:len(mess)]==mess):\n",
        "        improved_tests=improved_tests[len(mess):]\n",
        "\n",
        "    if(improved_tests[:3]==\"```\"):\n",
        "        improved_tests = improved_tests[9:-3]\n",
        "\n",
        "    openai_test_file = 'test_openai_' + module_name.replace('.', '_') + '.py'\n",
        "\n",
        "    with open(openai_test_file, 'w') as file:\n",
        "        file.write(improved_tests)\n",
        "\n",
        "    combined_test_file = 'combined_tests.py'\n",
        "\n",
        "    with open(combined_test_file, 'w') as outfile:\n",
        "        for fname in [pynguin_test_file, openai_test_file]:\n",
        "            with open(fname) as infile:\n",
        "                outfile.write(infile.read())\n",
        "                outfile.write(\"\\n\")\n",
        "\n",
        "    previous_missed_statements = set()\n",
        "    with open(combined_test_file, 'r') as file:\n",
        "        testcase_code = file.read()\n",
        "    improved_tests=testcase_code\n",
        "    while True:\n",
        "        evaluate_coverage(combined_test_file)\n",
        "        new_missed_statements = set(get_missed_statements('analysis_report.txt'))\n",
        "\n",
        "        if not new_missed_statements or new_missed_statements == previous_missed_statements:\n",
        "            break\n",
        "\n",
        "        previous_missed_statements = new_missed_statements\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        The following is a Python program:\n",
        "\n",
        "        {code}\n",
        "\n",
        "        The current test cases are missing coverage of the above code for the following statements: {missed_statements}.\n",
        "        Please modify this exsisting testcases that cover these missed statements.\n",
        "        Exsisting testcases: {testcase_code}\n",
        "\n",
        "        Clearly mention the name of the module to be used take the reference from file path: {file_path}\n",
        "\n",
        "        Do not give text apart from code. Note it is very important that you give code only do not generate anything else apart from code.\n",
        "        \"\"\"\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7,\n",
        "            max_tokens=1500,\n",
        "            top_p=0.9,\n",
        "        )\n",
        "\n",
        "\n",
        "        improved_tests = response.choices[0].message.content.strip()\n",
        "        if(improved_tests[:65]==\"Here is the unit test code that covers all the missed statements:\"):\n",
        "            improved_tests=improved_tests[65:]\n",
        "        if(improved_tests[:3]==\"```\"):\n",
        "            improved_tests=improved_tests[9:-3]\n",
        "        filename=combined_test_file\n",
        "\n",
        "        with open(filename, 'w') as file:\n",
        "            file.write(improved_tests)\n",
        "\n",
        "\n",
        "    return improved_tests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d44a930b-2b8f-404d-b2cf-e3412ae72211",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d44a930b-2b8f-404d-b2cf-e3412ae72211",
        "outputId": "4cf3db7f-76db-46bd-8735-79bcbdd2461d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.2.2, pluggy-1.5.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content\n",
            "plugins: anyio-3.7.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 13 items                                                                                 \u001b[0m\n",
            "\n",
            "combined_tests.py::test_case_0 \u001b[33mXFAIL\u001b[0m\u001b[32m                                                         [  7%]\u001b[0m\n",
            "combined_tests.py::test_case_1 \u001b[32mPASSED\u001b[0m\u001b[32m                                                        [ 15%]\u001b[0m\n",
            "combined_tests.py::test_case_2 \u001b[33mXFAIL\u001b[0m\u001b[32m                                                         [ 23%]\u001b[0m\n",
            "combined_tests.py::test_case_3 \u001b[33mXFAIL\u001b[0m\u001b[32m                                                         [ 30%]\u001b[0m\n",
            "combined_tests.py::test_case_4 \u001b[33mXFAIL\u001b[0m\u001b[32m                                                         [ 38%]\u001b[0m\n",
            "combined_tests.py::test_case_5 \u001b[33mXFAIL\u001b[0m\u001b[32m                                                         [ 46%]\u001b[0m\n",
            "combined_tests.py::test_case_6 \u001b[33mXFAIL\u001b[0m\u001b[32m                                                         [ 53%]\u001b[0m\n",
            "combined_tests.py::test_sum \u001b[32mPASSED\u001b[0m\u001b[32m                                                           [ 61%]\u001b[0m\n",
            "combined_tests.py::test_mean \u001b[32mPASSED\u001b[0m\u001b[32m                                                          [ 69%]\u001b[0m\n",
            "combined_tests.py::test_median_even \u001b[32mPASSED\u001b[0m\u001b[32m                                                   [ 76%]\u001b[0m\n",
            "combined_tests.py::test_median_odd \u001b[32mPASSED\u001b[0m\u001b[32m                                                    [ 84%]\u001b[0m\n",
            "combined_tests.py::test_variance \u001b[32mPASSED\u001b[0m\u001b[32m                                                      [ 92%]\u001b[0m\n",
            "combined_tests.py::test_standard_deviation \u001b[32mPASSED\u001b[0m\u001b[32m                                            [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m=================================== \u001b[32m\u001b[1m7 passed\u001b[0m, \u001b[33m6 xfailed\u001b[0m\u001b[32m in 0.07s\u001b[0m\u001b[32m ===================================\u001b[0m\n",
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.2.2, pluggy-1.5.0\n",
            "rootdir: /content\n",
            "plugins: anyio-3.7.1\n",
            "collected 13 items                                                                                 \u001b[0m\n",
            "\n",
            "combined_tests.py \u001b[33mx\u001b[0m\u001b[32m.\u001b[0m\u001b[33mx\u001b[0m\u001b[33mx\u001b[0m\u001b[33mx\u001b[0m\u001b[33mx\u001b[0m\u001b[33mx\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                              [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m=================================== \u001b[32m\u001b[1m7 passed\u001b[0m, \u001b[33m6 xfailed\u001b[0m\u001b[32m in 0.10s\u001b[0m\u001b[32m ===================================\u001b[0m\n",
            "Wrote JSON report to coverage.json\n",
            "Name                Stmts   Miss  Cover   Missing\n",
            "-------------------------------------------------\n",
            "combined_tests.py      61      0   100%\n",
            "processor.py           19      0   100%\n",
            "-------------------------------------------------\n",
            "TOTAL                  80      0   100%\n",
            "File: combined_tests.py\n",
            "Executable Lines: [3, 4, 5, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 59, 60, 62, 63, 64, 66, 67, 68, 70, 71, 72, 74, 75, 76, 78, 79, 80, 82, 83, 84]\n",
            "Executed Lines: [3, 4, 5, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 59, 60, 62, 63, 64, 66, 67, 68, 70, 71, 72, 74, 75, 76, 78, 79, 80, 82, 83, 84]\n",
            "Missed Lines: []\n",
            "Excluded Lines: []\n",
            "[]\n",
            "# Test cases automatically generated by Pynguin (https://www.pynguin.eu).\n",
            "# Please check them before you use them.\n",
            "import pytest\n",
            "import processor as module_0\n",
            "import builtins as module_1\n",
            "\n",
            "\n",
            "@pytest.mark.xfail(strict=True)\n",
            "def test_case_0():\n",
            "    set_0 = set()\n",
            "    data_processor_0 = module_0.DataProcessor(set_0)\n",
            "    data_processor_0.median()\n",
            "\n",
            "\n",
            "def test_case_1():\n",
            "    bytes_0 = b\"\\xa8@U\\xdb<\\xae\\xd1T\\xe3\\x14\\xfan\\x81\\xe2Xd\\xf7\\x82\\xad\"\n",
            "    data_processor_0 = module_0.DataProcessor(bytes_0)\n",
            "    var_0 = data_processor_0.median()\n",
            "    assert var_0 == 130\n",
            "\n",
            "\n",
            "@pytest.mark.xfail(strict=True)\n",
            "def test_case_2():\n",
            "    bytes_0 = b\"\\xfd\\xef\\xb4\\xa76.\\xa8\"\n",
            "    data_processor_0 = module_0.DataProcessor(bytes_0)\n",
            "    var_0 = data_processor_0.variance()\n",
            "    assert var_0 == pytest.approx(5658.693877551021, abs=0.01, rel=0.01)\n",
            "    var_0.variance()\n",
            "\n",
            "\n",
            "@pytest.mark.xfail(strict=True)\n",
            "def test_case_3():\n",
            "    none_type_0 = None\n",
            "    data_processor_0 = module_0.DataProcessor(none_type_0)\n",
            "    data_processor_0.sum()\n",
            "\n",
            "\n",
            "@pytest.mark.xfail(strict=True)\n",
            "def test_case_4():\n",
            "    object_0 = module_1.object()\n",
            "    data_processor_0 = module_0.DataProcessor(object_0)\n",
            "    data_processor_0.mean()\n",
            "\n",
            "\n",
            "@pytest.mark.xfail(strict=True)\n",
            "def test_case_5():\n",
            "    tuple_0 = ()\n",
            "    set_0 = {tuple_0, tuple_0, tuple_0}\n",
            "    data_processor_0 = module_0.DataProcessor(set_0)\n",
            "    data_processor_0.variance()\n",
            "\n",
            "\n",
            "@pytest.mark.xfail(strict=True)\n",
            "def test_case_6():\n",
            "    none_type_0 = None\n",
            "    data_processor_0 = module_0.DataProcessor(none_type_0)\n",
            "    data_processor_0.standard_deviation()\n",
            "\n",
            "import pytest\n",
            "from processor import DataProcessor\n",
            "\n",
            "def test_sum():\n",
            "    data_processor = DataProcessor([1, 2, 3, 4, 5])\n",
            "    assert data_processor.sum() == 15\n",
            "\n",
            "def test_mean():\n",
            "    data_processor = DataProcessor([1, 2, 3, 4, 5])\n",
            "    assert data_processor.mean() == 3\n",
            "\n",
            "def test_median_even():\n",
            "    data_processor = DataProcessor([1, 2, 3, 4])\n",
            "    assert data_processor.median() == 2.5\n",
            "\n",
            "def test_median_odd():\n",
            "    data_processor = DataProcessor([1, 2, 3, 4, 5])\n",
            "    assert data_processor.median() == 3\n",
            "\n",
            "def test_variance():\n",
            "    data_processor = DataProcessor([1, 2, 3, 4, 5])\n",
            "    assert data_processor.variance() == 2.0\n",
            "\n",
            "def test_standard_deviation():\n",
            "    data_processor = DataProcessor([1, 2, 3, 4, 5])\n",
            "    assert data_processor.standard_deviation() == 1.4142135623730951\n",
            "\n"
          ]
        }
      ],
      "source": [
        "improved_tests = iterative_improvement('processor.py','processor')\n",
        "print(improved_tests)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f01cac47-0e2a-400d-abcd-1769532e00d4",
      "metadata": {
        "id": "f01cac47-0e2a-400d-abcd-1769532e00d4"
      },
      "source": [
        "# Approach 3: Reasoning Generation and Review (Used to Identify the logic behind test cases and Help in improving them)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "36c1ca01-638d-4016-a32e-cd00043d14ea",
      "metadata": {
        "id": "36c1ca01-638d-4016-a32e-cd00043d14ea"
      },
      "outputs": [],
      "source": [
        "def generate_tests_with_reasoning(file_path):\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        function_code = file.read()\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    The following is a Python program:\n",
        "\n",
        "    {function_code}\n",
        "\n",
        "    Write Unit tests using Pytest with Reasoning for given Python code that covers all the edge cases.\n",
        "    Give Unit tests only and Reasoning and no additional text.\n",
        "\n",
        "    Clearly mention the name of the module to be used take the reference from file path: {file_path}\n",
        "    ###Do not include this line in generated tests: \"```python\n",
        "    \"\"\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=800,\n",
        "        top_p=0.9,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "dafa10ae-2223-44d6-827b-468451310eb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dafa10ae-2223-44d6-827b-468451310eb5",
        "outputId": "a098c9f8-bc9a-43f7-dd16-666d487129e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "import os\n",
            "import pytest\n",
            "from file_operations import FileManager\n",
            "\n",
            "\n",
            "def test_create_file(tmpdir):\n",
            "    base_dir = tmpdir.mkdir(\"sub\")\n",
            "    file_manager = FileManager(base_dir)\n",
            "    file_name = \"test.txt\"\n",
            "    content = \"This is a test file.\"\n",
            "\n",
            "    # Test that the file is created in the correct location with the correct content\n",
            "    assert file_manager.create_file(file_name, content) == os.path.join(base_dir, file_name)\n",
            "    with open(os.path.join(base_dir, file_name), 'r') as file:\n",
            "        assert file.read() == content\n",
            "\n",
            "def test_read_file(tmpdir):\n",
            "    base_dir = tmpdir.mkdir(\"sub\")\n",
            "    file_manager = FileManager(base_dir)\n",
            "    file_name = \"test.txt\"\n",
            "    content = \"This is a test file.\"\n",
            "\n",
            "    # Create a file to read\n",
            "    with open(os.path.join(base_dir, file_name), 'w') as file:\n",
            "        file.write(content)\n",
            "\n",
            "    # Test that the content of the file is read correctly\n",
            "    assert file_manager.read_file(file_name) == content\n",
            "\n",
            "def test_delete_file(tmpdir):\n",
            "    base_dir = tmpdir.mkdir(\"sub\")\n",
            "    file_manager = FileManager(base_dir)\n",
            "    file_name = \"test.txt\"\n",
            "\n",
            "    # Create a file to delete\n",
            "    with open(os.path.join(base_dir, file_name), 'w') as file:\n",
            "        file.write(\"\")\n",
            "\n",
            "    # Test that the file is deleted correctly\n",
            "    assert file_manager.delete_file(file_name) == True\n",
            "    # Test that the file is not present after deletion\n",
            "    assert not os.path.exists(os.path.join(base_dir, file_name))\n",
            "\n",
            "def test_list_files(tmpdir):\n",
            "    base_dir = tmpdir.mkdir(\"sub\")\n",
            "    file_manager = FileManager(base_dir)\n",
            "    file_names = [\"test1.txt\", \"test2.txt\", \"test3.txt\"]\n",
            "\n",
            "    # Create some files\n",
            "    for file_name in file_names:\n",
            "        with open(os.path.join(base_dir, file_name), 'w') as file:\n",
            "            file.write(\"\")\n",
            "\n",
            "    # Test that all files are listed correctly\n",
            "    assert set(file_manager.list_files()) == set(file_names)\n",
            "```\n",
            "\n",
            "Reasoning:\n",
            "\n",
            "- `test_create_file` tests the `create_file` method. It checks that a file is created at the correct location and that the content of the file is correct.\n",
            "- `test_read_file` tests the `read_file` method. It checks that the content of a file is read correctly.\n",
            "- `test_delete_file` tests the `delete_file` method. It checks that a file is deleted correctly and that the file does not exist after deletion.\n",
            "- `test_list_files` tests the `list_files` method. It checks that all files in the base directory are listed correctly.\n"
          ]
        }
      ],
      "source": [
        "print(generate_tests_with_reasoning('file_operations.py'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24de8b3a-b4f5-4c77-9fa9-529094442e42",
      "metadata": {
        "id": "24de8b3a-b4f5-4c77-9fa9-529094442e42"
      },
      "source": [
        "# Approach 4: Iterative Improvement till Complete Coverage of Source Code by Unit Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "28beddd3-23da-4b8d-b274-1d79c832a80e",
      "metadata": {
        "id": "28beddd3-23da-4b8d-b274-1d79c832a80e"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "def get_missed_statements(report_path):\n",
        "    \"\"\"\n",
        "    Extracts missed statements from a coverage report in a text file.\n",
        "\n",
        "    Parameters:\n",
        "    report_path (str): The path to the text coverage report file.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of missed statements.\n",
        "    \"\"\"\n",
        "    missed_statements = []\n",
        "\n",
        "    with open(report_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Regular expression to match the missed lines\n",
        "    missed_lines_pattern = re.compile(r\"Missed lines:\\s*\\[([0-9,\\s]*)\\]\")\n",
        "\n",
        "    for line in lines:\n",
        "        match = missed_lines_pattern.search(line)\n",
        "        if match:\n",
        "            missed_lines_str = match.group(1).strip()\n",
        "            if missed_lines_str:\n",
        "                missed_lines = [int(x.strip()) for x in missed_lines_str.split(',') if x.strip().isdigit()]\n",
        "                missed_statements.extend(missed_lines)\n",
        "\n",
        "    print(missed_statements)\n",
        "    return missed_statements\n",
        "\n",
        "\n",
        "def iterative_improvement(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        code = file.read()\n",
        "\n",
        "    missed_statements = []\n",
        "    improved_tests = generate_test_cases(file_path)\n",
        "    if(improved_tests[:65]==\"Here is the unit test code that covers all the missed statements:\"):\n",
        "        improved_tests=improved_tests[65:]\n",
        "    if(improved_tests[:3]==\"```\"):\n",
        "        improved_tests=improved_tests[9:-3]\n",
        "    filename=f'test_{os.path.basename(file_path)}'\n",
        "    if not filename.endswith('.py'):\n",
        "            filename += '.py'\n",
        "\n",
        "    # Write the code string to the file\n",
        "    print(filename)\n",
        "    with open(filename, 'w') as file:\n",
        "        file.write(improved_tests)\n",
        "\n",
        "\n",
        "\n",
        "    while True:\n",
        "        evaluate_coverage(filename)\n",
        "        new_missed_statements = get_missed_statements('analysis_report.txt')  # Implement this function based on your coverage tool\n",
        "\n",
        "        if not new_missed_statements or new_missed_statements == missed_statements:\n",
        "            break\n",
        "\n",
        "        missed_statements = new_missed_statements\n",
        "        prompt = f\"\"\"\n",
        "        The following is a Python program:\n",
        "\n",
        "        {code}\n",
        "\n",
        "        The current test cases are missing coverage for the following statements: {missed_statements}.\n",
        "        Please generate new unit tests using Pytest that cover these missed statements.\n",
        "\n",
        "        Clearly mention the name of the module to be used take the reference from file path: {file_path}\n",
        "\n",
        "        Do not give text apart from code. Note it is very important that you give code only do not generate anything else apart from code.\n",
        "        \"\"\"\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7,\n",
        "            max_tokens=1500,\n",
        "            top_p=0.9,\n",
        "        )\n",
        "\n",
        "\n",
        "        improved_tests=response.choices[0].message.content.strip()\n",
        "        if(improved_tests[:65]==\"Here is the unit test code that covers all the missed statements:\"):\n",
        "            improved_tests=improved_tests[65:]\n",
        "        if(improved_tests[:3]==\"```\"):\n",
        "            improved_tests=improved_tests[9:-3]\n",
        "\n",
        "        with open(filename, 'w') as file:\n",
        "            file.write(improved_tests)\n",
        "\n",
        "    return improved_tests\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "19bbf932-3245-4eda-bff8-1c68f7b739c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19bbf932-3245-4eda-bff8-1c68f7b739c1",
        "outputId": "95a1a9ee-ed71-4b9b-ce65-6b1e724028ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_file_operations.py\n",
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.2.2, pluggy-1.5.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content\n",
            "plugins: anyio-3.7.1\n",
            "collected 5 items                                                                                  \u001b[0m\n",
            "\n",
            "test_file_operations.py::test_create_file \u001b[32mPASSED\u001b[0m\u001b[32m                                             [ 20%]\u001b[0m\n",
            "test_file_operations.py::test_read_file \u001b[32mPASSED\u001b[0m\u001b[32m                                               [ 40%]\u001b[0m\n",
            "test_file_operations.py::test_delete_file \u001b[32mPASSED\u001b[0m\u001b[32m                                             [ 60%]\u001b[0m\n",
            "test_file_operations.py::test_delete_non_existent_file \u001b[32mPASSED\u001b[0m\u001b[32m                                [ 80%]\u001b[0m\n",
            "test_file_operations.py::test_list_files \u001b[32mPASSED\u001b[0m\u001b[32m                                              [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m======================================== \u001b[32m\u001b[1m5 passed\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[32m =========================================\u001b[0m\n",
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.2.2, pluggy-1.5.0\n",
            "rootdir: /content\n",
            "plugins: anyio-3.7.1\n",
            "collected 5 items                                                                                  \u001b[0m\n",
            "\n",
            "test_file_operations.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m======================================== \u001b[32m\u001b[1m5 passed\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[32m =========================================\u001b[0m\n",
            "Wrote JSON report to coverage.json\n",
            "Name                      Stmts   Miss  Cover   Missing\n",
            "-------------------------------------------------------\n",
            "file_operations.py           21      0   100%\n",
            "test_file_operations.py      34      0   100%\n",
            "-------------------------------------------------------\n",
            "TOTAL                        55      0   100%\n",
            "File: test_file_operations.py\n",
            "Executable Lines: [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
            "Executed Lines: [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
            "Missed Lines: []\n",
            "Excluded Lines: []\n",
            "[]\n",
            "\n",
            "import os\n",
            "import pytest\n",
            "from file_operations import FileManager\n",
            "\n",
            "def test_create_file(tmpdir):\n",
            "    base_dir = tmpdir.mkdir(\"subdir\")\n",
            "    fm = FileManager(base_dir)\n",
            "    file_path = fm.create_file(\"test_file.txt\", \"Hello, World!\")\n",
            "    assert os.path.exists(file_path)\n",
            "    with open(file_path, 'r') as file:\n",
            "        assert file.read() == \"Hello, World!\"\n",
            "\n",
            "def test_read_file(tmpdir):\n",
            "    base_dir = tmpdir.mkdir(\"subdir\")\n",
            "    fm = FileManager(base_dir)\n",
            "    file_path = fm.create_file(\"test_file.txt\", \"Hello, World!\")\n",
            "    assert fm.read_file(\"test_file.txt\") == \"Hello, World!\"\n",
            "\n",
            "def test_delete_file(tmpdir):\n",
            "    base_dir = tmpdir.mkdir(\"subdir\")\n",
            "    fm = FileManager(base_dir)\n",
            "    file_path = fm.create_file(\"test_file.txt\", \"Hello, World!\")\n",
            "    assert fm.delete_file(\"test_file.txt\")\n",
            "    assert not os.path.exists(file_path)\n",
            "\n",
            "def test_delete_non_existent_file(tmpdir):\n",
            "    base_dir = tmpdir.mkdir(\"subdir\")\n",
            "    fm = FileManager(base_dir)\n",
            "    assert not fm.delete_file(\"non_existent_file.txt\")\n",
            "\n",
            "def test_list_files(tmpdir):\n",
            "    base_dir = tmpdir.mkdir(\"subdir\")\n",
            "    fm = FileManager(base_dir)\n",
            "    file_path1 = fm.create_file(\"test_file1.txt\", \"Hello, World!\")\n",
            "    file_path2 = fm.create_file(\"test_file2.txt\", \"Hello, Python!\")\n",
            "    files = fm.list_files()\n",
            "    assert len(files) == 2\n",
            "    assert \"test_file1.txt\" in files\n",
            "    assert \"test_file2.txt\" in files\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "improved_tests = iterative_improvement('file_operations.py')\n",
        "print(improved_tests)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
